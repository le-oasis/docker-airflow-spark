version: '3'
services:
   # Jupyter notebook
  jupyter-spark:
        hostname: myjupyter
        container_name: jupyter_container
        image: 'jupyter/pyspark-notebook:latest'
        networks:
            - oasiscorp
        ports:
          - "8888:8888"
        #   - "4040-4080:4040-4080"
        volumes:
          - ../notebooks:/home/jovyan/work/notebooks/
          - ../spark/resources/data:/home/jovyan/work/data/
          - ../spark/resources/jars:/home/jovyan/work/jars/
        restart: always



  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    ports:
      - "8181:8080"
      - "7077:7077"
      - "4040:4040"
    volumes:
        - ../spark/app:/usr/local/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
        - ../spark/resources:/usr/local/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)
    networks:
        - oasiscorp
    environment:
      - INIT_DAEMON_STEP=setup_spark
  
  spark-worker-1:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-1
    depends_on:
      - spark-master
    # ports:
    #   - "8081:8081"
    volumes:
       - ../spark/app:/usr/local/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
       - ../spark/resources:/usr/local/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)
    networks:
        - oasiscorp
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
  
  spark-worker-2:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-2
    depends_on:
      - spark-master
    # ports:
    #   - "8082:8081"
    volumes:
        - ../spark/app:/usr/local/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
        - ../spark/resources:/usr/local/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)
    networks:
        - oasiscorp
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"

  spark-worker-3:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-3
    depends_on:
      - spark-master
    # ports:
    #   - "8083:8081"
    volumes:
        - ../spark/app:/usr/local/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
        - ../spark/resources:/usr/local/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)
    networks:
        - oasiscorp
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
  

     
networks:
  oasiscorp:
    driver: bridge

