version: '3'
services:

  minio:
        hostname: myminio
        container_name: minio_container
        image: 'bitnami/minio:latest' # latest image as of 2021-11-08
        environment:
            MINIO_ACCESS_KEY: minio_admin
            MINIO_SECRET_KEY: minio_password
        ports:
            - '9000:9000'
            - '9001:9001'
        volumes:
            - '../minio/data:/data'
        networks:
            - oasiscorp
        healthcheck:
            test: ["CMD", "curl", "-f", "http://myminio:9000/minio/health/live"]
            interval: 30s
            timeout: 20s
            retries: 3
        restart: always


   # Jupyter notebook
  jupyter-spark:
        hostname: myjupyter
        container_name: jupyter_container
        image: 'jupyter/pyspark-notebook:latest'
        networks:
            - oasiscorp
        ports:
          - "8888:8888"
        #   - "4040-4080:4040-4080"
        volumes:
          - ../notebooks:/home/jovyan/work/notebooks/
          - ../spark/resources/data:/home/jovyan/work/data/
          - ../spark/resources/jars:/home/jovyan/work/jars/
        restart: always



  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
      - "4040:4040"
    volumes:
        - ../spark/app:/usr/local/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
        - ../spark/resources:/usr/local/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)
    networks:
        - oasiscorp
    environment:
      - INIT_DAEMON_STEP=setup_spark
  
  spark-worker-1:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    volumes:
       - ../spark/app:/usr/local/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
       - ../spark/resources:/usr/local/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)
    networks:
        - oasiscorp
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
  
  spark-worker-2:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    volumes:
        - ../spark/app:/usr/local/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
        - ../spark/resources:/usr/local/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)
    networks:
        - oasiscorp
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"

  spark-worker-3:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-3
    depends_on:
      - spark-master
    ports:
      - "8083:8081"
    volumes:
        - ../spark/app:/usr/local/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
        - ../spark/resources:/usr/local/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)
    networks:
        - oasiscorp
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
  


        
networks:
  oasiscorp:
    driver: bridge

